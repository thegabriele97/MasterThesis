\nocite{doi:10.1063/1.5127719}
\nocite{STERPONE20152087}
\nocite{1545891}
\nocite{7948546}
\nocite{8093203}
\nocite{ecss1}
\nocite{nasa2}

\chapter{General Background}
\label{sec:background}

Before going further with the problem analysis, it is better to introduce a few background concepts. In particular how FPGAs work, what kind of radiations exists and how FPGAs are affected by them.  

\section{Hardware Technology}

\subsection{FPGA Architecture}
\label{sec:fpgaarchitecture}
Field Programmable Gate Arrays \textit{FPGAs} are used in a wide range of applications, from signal processing to machine learning applications. In particular, it is an integrated circuit designed to be general-purpose: after manufacturing, it has no functionalities. It is hardware that can be programmed to perform specific tasks. \bigskip

It differs from a CPU, which is an already designed hardware. A CPU does only one thing in a very optimized way: execute code, from a pre-defined Instruction Set. In this case, the action of \textit{programming} is referred to as the process of writing a series of instructions that the CPU will eventually execute. This is done by exploiting Programming Languages. An FPGA, instead, is like LEGO bricks. Each LEGO brick does not have any function or purpose alone, but when put together with other bricks, it can be used to perform a specific task. Here, the action of \textit{programming} is referred to the process of writing a \textit{description} on how all the bricks must be assembled to perform the specific task we want. The description is done by exploiting Hardware Description Languages (HDL) like VHDL or Verilog. \bigskip

The basic FPGA design consists of I/O pads (to connect with the outside world), a set of routing channels and a set of \textit{LEGO bricks}. A \textit{LEGO brick} in the FPGA is a logic block (and depending on the vendor, it can be called CLB or LAB) that can be programmed to perform a very specific task that helps in achieving the goal of the User's Application in the overall design. 

\begin{figure}[H]
\centering
\includegraphics[width=1.0\linewidth]{images/chapter2/FPGA_cell_example.png}
\caption{Simplified schematic of an FPGA cell}
\label{fig:fpga_cell}
\end{figure}

A basic logic block consists of a few Logic Elements. As shown in figure \ref{fig:fpga_cell}, a Logic Elements is made of LUTs, a Full-Adder (FA), a D-Type Flip Flop and a bunch of multiplexers. This particular architecture can work in two modes: \textit{normal} mode and \textit{arithmetic} mode. Thanks to the Flip Flop, FPGAs can implement operations where some kind of memory is required.\bigskip

Modern FPGAs are very complex and expand upon the above capabilities to include other functionalities in silicon. Those are commonly used functions embedded in the circuit. They reduce the overall area required and give those functions increased speed compared to building them from logical primitives (because are implemented in silicon, and built out of transistor instead of LUTs, enabling ASICs-level performance). Examples of these include multipliers, generic DSP blocks, embedded processors, high-speed I/O logic (like PCI/PCI-Express controllers, DRAM Controllers and so on and so forth) and embedded memories. \bigskip

Once the User completes the design (i.e. the description of the FPGA is written using some HDL language), the design needs to be mapped on top of the FPGA's hardware resources. This is done using the Vendor's specific software and it is in charge of deciding which FPGA's Logic Element (LE) is assigned to which subpart of the description and how each LE is configured. Then, all the LEs needs to be connected among themselves and the I/O pads, and this is done by routing algorithms that decide the best way to connect them. Once all the implementation steps are done, a configuration file is generated that will eventually be used to program the FPGA and is called \textit{bitstream}.\bigskip

All the programmable bits (like the content of the LUTs, some multiplexers selection signals or the routing details) are stored in the FPGA in memory elements that are outside the FPGA's functional blocks (i.e. the ones that can be used by the user to implement the application). Those memory elements can be thought of as a big array of bits, or a \textit{shift register}. It is the \textit{configuration memory}: it stores the configuration bits of the entire FPGA and is loaded with the bitstream when the FPGA itself is programmed. Most FPGAs rely on an SRAM-based approach to be programmed: this allows them to be in-system programmable (so the FPGA chip can be programmed without unmounting it from the board and from the system itself) and re-programmable (can be programmed as many times we want), but require external boot devices. When the FPGA is powered off, the configuration memory content is lost because the SRAM is a volatile memory. Hence, it requires an external memory where the bitstream can be retrieved to re-program it. The SRAM approach is based on the Complementary Metal-Oxide-Semiconductor(CMOS) technology.\bigskip

Consequently, FPGAs are alternatives to hard-core CPUs. This means that a CPU can be implemented out of logic primitives on an FPGA and is defined as \textit{soft-core}, alongside the hardware that is used to implement the application like peripherals, memory and other components. Modern FPGAs support \textit{at runtime programming}, this lead to the idea of \textit{reconfigurable systems}, where for example a CPU can be reconfigured in order to enable/disable some of its functionalities to suit the task at hand. The concept of \textit{reconfigurable systems} is also used in another manner and will be explained further in the next chapters.

\subsection{FPGAs vs. ASICs}

An \textit{ASIC} (application-specific integrated circuit) is an integrated circuit chip customized for a particular use. ASIC chips are typically fabricated using metal-oxide-semiconductor (MOS) technology. Thanks to the miniaturization of the MOS-based transistors and the improvement in the design tools, the maximum complexity (and hence functionality) possible in an ASIC has grown from 5000 logic gates to over 100 million. \bigskip

They are designed using the same HDLs Languages as the FPGAs, but the similarities stop there. Once the description is complete, specific ASIC softwares are used to synthesize and implement on top of a technology library. While the corresponding technology library in FPGAs is simpler (made of LEs and routing elements), on ASICs it is a lot more complex. A typical ASIC technology library consists of a set of basic logic gates (like 2 input NAND, 3 input OR, 2 input Full Adder (FA), etc.) provided by the manufacturer that assembles the chip. Once an HDL description is mapped on top of the ASIC library, the so-called \textit{gate-level netlist} is sent to the manufacturer. Here, ad-hoc technicians will start to work on this netlist, doing the \textit{route} {\&} \textit{place} of the netlist and as an output of this process, a set of masks is generated. The masks are used to \textit{print} the circuit on the silicon. On top of all this process, test engineers must prepare a set of tests in order to verify the correct functionalities of the circuit during the various stages of the manufacturing process, until the end of the process itself. \bigskip

This allows the implementation of entire microprocessors, memories (including ROM, RAM, EEPROM and flash) and other large components in a single chip. Usually, for lower production volumes, FPGAs may be more cost-effective than an ASIC design. This is due to the non-recurring engineering (NRE) cost of an ASIC, which can run into millions of dollars. \bigskip

To recap:
\begin{itemize}
    \item ASICs circuits are faster, and less power-hungry than FPGAs.
    \item ASICs are more complex to design and implement (hence more expensive) than FPGAs.
    \item FPGAs are more flexible than ASICs.
\end{itemize}


\subsection{FPGA or ASIC in Aerospace Applications?}

In the aerospace industry, we are witnessing a turnaround in the last years regarding hardware technology. FPGAs are typically much less radiation-hardened than ASICs, so they are more prone to SEUs as well as lower total ionizing dose tolerance, but there are techniques to reduce these deficiencies. However, FPGAs are used on a lot more missions nowadays than 15 years ago, for all the reasons that make FPGAs a better choice than ASICs.\bigskip

As an example, Mars Exploration Rovers were something like 90\% ASICS. The last JPL's Martian Rover, Perseverance, is a very complex system and it is a very challenging design from the engineering point of view: it has multiple sensors and cameras to collect as much data as possible and, due to the volume of live data being recorded and the long data transmission time from Mars to Earth, a powerful processing system is essential. Early Mars rovers were basing their workload mainly on CPUs and ASICs as the processing units, while nowadays FPGAs are taking on much of the workload, like in Perseverance.\bigskip

There are different reasons behind this choice. The first one is the flexibility given by their re-programmability: because of the different stages a mission is made of, some parts of the system could be useful only in some of those stages (maybe intermediate ones) and they will never be used again. This is a waste of resources: FPGAs can give great help in this aspect and Perseverance rover is an example. It utilizes an almost two decades old FPGA technology (Xilinx Virtex-5, introduced in May 2006 on 65 nm technology) as one of the main processing units. This unit is responsible for rover entry, descent and landing on Mars. Once the rover landed, this unit would be useless becoming a \textit{dead hardware}. However, it is based on FPGA hardware so it has been reprogrammed by NASA engineers from Earth to handle computer vision tasks.\bigskip

Other units on Perseverance such as radars, cameras, UHF transceivers, radar, and X-rays (used to identify chemicals) are controlled using Xilinx's FPGAs. Another interesting point is that Perseverance uses machine learning algorithms running on FPGAs, and they are so well optimized that it is achieving higher performance levels (about 18 times) than the Curiosity rover (which landed on Mars in 2012 and is still active). \bigskip

Another advantage of using FPGAs is the faster time-to-space. Different points help in achieving this advantage. Not only the development on FPGA is faster than on ASICs (cost of design, development and fabrication of an ASIC are not present), but the most important thing is that there are many and many changes in the processing unit architecture during the project development phase. There is usually a very restricted launch window for the mission that can be missed, and FPGAs help in two ways mainly:

\begin{itemize}
    \item Physically changing or adding more to a space system is a real challenge. The installation itself is not that difficult, but the system has to be recertified, proving that it is still dependable. Furthermore, FPGAs simplify this greatly: the only thing to prove is that the FPGA chip is safe to fly with. Once this is done, the overall number of different parts to be certified is reduced. Second, a bitstream or software change takes a lot less time to certify.
    \item Software and Hardware development can be done in parallel. This is a great advantage for the software development team because a first iteration of the hardware can be prepared and ready to be used by the software team faster and the software team can start to work on the software itself.
\end{itemize}

FPGAs are not only helpful during the development phase, but even during the operational phase. Missions are prepared to last a relatively long time, but usually, the quality of the work is so high that they last much longer. Examples are Mars rovers: Opportunity landed on the Red Planet in 2003 and it was ended by a Martian dust storm in 2018, so it lasted for 15 years. Curiosity in 2012 and in 2022 is still active. This is a so long period that, speaking again about \textit{re-programmibility}, the processing system architecture may require changes to let the mission continue working. Different things can go wrong in a decade and having a fully reconfigurable system (from remote in particular) is a must, giving ground engineers a lot more possibilities to fix the system or to add/remove components. \bigskip

On the radiation-tolerant side, vendors offer radiation-tolerant FPGAs. On top of that, it is possible to apply some logic changes to the design like TMR (Triple Module Redundancy) to a portion of the design or even to the entire design. Basically, it consists in triplicating the design and adding a voter at the outputs. If a radiation error occurs, it will theoretically affect only one module so there will be two different results from the three modules (two correct and one wrong caused by the radiation). The voter will select the correct result (that is the majority). This is an example of making a design more robust to radiation.\bigskip

\section{Radiations}

We are going to understand better why radiation effects regarding electronic devices are one of the primary concerns for the aerospace industry.\bigskip

\subsection{Radiation sources}
Where does the radiation originate from? Unfortunately, the Universe and in particular the Solar System are full of radiations. The natural space radiation environment can damage electronic devices in different ways, ranging from degradation in performance to a complete functional failure. More and more a space system goes deeper in space, and less and less it is protected by the Earth's atmosphere.\bigskip

Close to the Earth, there are three sources of radiation: the Van Allen Belts, the Sun and the Cosmos itself. Van Allen Belts are zones of energetic charged particles, that are generated for example by the Sun, and captured by the Earth's magnetosphere. By trapping those charged particles, the magnetic field deflects them and protects the atmosphere from destruction. The two Earth's main belts extend from an altitude of 640 km to 58.000 km, in which radiation levels vary. Between the two belts, the \textit{inner} and the \textit{outer} there is a zone called \textit{safe zone} where the level of radiation is pretty low. Spacecrafts traveling beyond the LEO (Low Earth Orbit) go through the two belts, and beyond the belts, they face additional hazards from cosmic rays and solar particle events (coronal mass ejections and solar flares).


\subsection{Radiation problems on Earth: the Super Mario 64 glitch}

Here on Earth, electronic devices are often not shielded or designed to tolerate radiations. Usually, only safety-critical systems undergo the same kind of radiation-tolerant techniques as the ones used in the space system, like Aviation and Nuclear Power Plants, for instance.\bigskip

Even if there is a big magnetosphere protecting the planet's surface, some charged particles still escape and travel until they reach the ground and some everyday devices. In 2013, a player was challenging another player in Nintendo's Super Mario 64 game. Suddenly, Mario was teleported into the air, saving crucial time and providing an incredible advantage in the game. The glitch caused the attention of a lot of players, and a \$1000 reward was offered to anyone who could replicate the glitch. Users tried in vain to recreate the scenario, but no one was able to emulate that giant leap. In the end, after eight years, users concluded that the glitch was not replicable because it was caused by a charged particle coming from the outer space that caused a bit-flip in the value that defines the player's height. \bigskip

Another curious case was the one related to the electronic voting machine in Belgium in 2003. A bit-flip here caused an adding of 4096 extra votes to a candidate. The error was only detected because there were more preferential votes than the candidate's list, which is impossible in the voting system. The official explanation was ``the spontaneous creation of a bit at the position 13 in the memory of the computer''. it is not a coincidence that the added value was exactly 4096, in hexadecimal \texttt{0x1000}, that is $2^{12}$.

\subsection{Types of radiation}
The most common way to classify radiations is based on their effects on electronic devices. If the effect is the result of cumulative damage (i.e. passage of many charged particles in different moments in time, and each particle has a relatively low energy) then it can be a \textit{total ionizing dose} or a \textit{displacement ionizing dose}. If the effect is the result of a single charged particle (with high energy) then it can be \textit{destructive} or \textit{non-destructive}, and they are usually referred to as SEE (Single Event Effects). \bigskip

\subsubsection{Total ionizing dose}
Most electronic devices are based on MOS transistors, forming the basis for digital logic. The common way to use those transistors is as \textit{electronic switches}: there are two isolated contacts, the source and the drain (i.e. the switch is off, no current). When a positive charge is applied to the gate (in the case of an NMOS transistor), electrons (that are negative charges) are allowed to pass from the two isolated contacts (i.e. the switch is on). \bigskip

When ionizing radiations pass through the device, electrons are moved away from the material leaving ``holes'' of missing charge, acting as positive charge carriers. These holes can find their way to the gate oxide and become trapped: this phenomenon is called \textit{total ionizing dose}. The effect of this phenomenon is the same as applying some positive voltage to the gate. With enough accumulated charges, the effect is to have the transistor always on, or better, in the \textit{stuck-on state}. \bigskip

\subsubsection{Displacement ionizing dose}
Another form of cumulative damage is the \textit{displacement ionizing dose}. This is the effect of a single charged particle passing through the device. What happens is that an atom is displaced from the material, modifying the crystal structure of the material itself. These microscopic effects create traps and recombination centers, eventually leading to the modification of the free flow of the current. This will ultimately impact the device's performance. \bigskip

\subsection{Single Event Effects}
When a single high-energy charged particle passes through the device, it can cause a \textit{destructive} or \textit{non-destructive} effect. The particle creates a momentary change of charge in the device, creating an unexpected current that can affect the device in various ways. Some effects may be completely destructive, while others may degrade performance to the point that the device doesn't work anymore within the limits required by the circuit or the system itself. Other effects cause the device to momentarily work in a wrong way, causing a functional failure (so it is not destructive from the point of view of the device but can cause a functional error, for example, a wrong value in the memory from \textit{0xe} to \textit{0xf}). \bigskip

Among the destructive effect, the most common are Single Event Latchup (SEL), Single Event Burnout (SEB) and Single Event Gate Rupture (SEGR).

\subsubsection{Single Event Latchup}
In CMOS technology, there are a lot of intrinsic BJT (Bipolar Junction Transistor). When a special arrangement of PMOS and NMOS transistors is used, resulting in an n-p-n-p structure (corresponding to an NPN and a PNP transistor stuck next to each other), a CMOS Latchup structure is created. If one of these two transistors is activated (accidentally by a high-energy charged particle), the other one will be activated too, creating a feedback loop. They will both keep each other activated for as long as some current flows through them. This phenomenon will increase the current draw and can bring to the destruction of the device. Usually, the only way to correct this situation is to make a \textit{power cycle}, so completely shutting down the device and then restarting it. However, latent damage may exist that may not appear until later. \bigskip

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{images/chapter2/Latchup.png}
\caption{The intrisic BJTs in the CMOS Technology that can cause a Latchup. Deepon, CC BY-SA 3.0, via Wikimedia Commons}
\label{fig:latchup}
\end{figure}

\subsubsection{Single Event Burnout}
Can happen when an incident particle initiates an avalanche charge multiplication effect. This leads to an increasing current, leading to a thermal runaway of the device, causing local melting or ejection of molten material in a small-scale explosion. Obviously, the result is the destruction of the device. \bigskip

\subsubsection{Single Event Gate Rupture}
SEGR is the destructive rupture of the gate oxide (or any dielectric layer in a transistor). The effects can be observed in power MOSFETs as an increase in the current flow when turned on, or in digital circuits with stuck bits. 

\subsubsection{Single Event Upset}
This is the most common non-destructive effect. As known as \textit{bit-flip}, it is caused by a particle that forces a digital signal to an opposite value momentarily. It can lean in a temporary modification of the digital output in a combinatory circuit, and the modified value can be memorized in a flip-flop or any other memory element if sampled at the same time radiation arrives. In more complex circuits, it can cause other malfunctions like resets and memory values modification. \bigskip

\begin{figure}[H]
\centering
\includegraphics[height=0.20\linewidth]{images/chapter2/SEU_EXAMPLE.pdf}
\caption{Example of a Single Event Upset in a memory element.}
\label{fig:seu_example}
\end{figure}

What is shown in Figure \ref{fig:seu_example} can for example happen in an SRAM memory. Each cell is made of cross-coupled transistors. Each side couple is connected forming an inverter (\textit{NOT} logic function), and the output of the inverter is connected to the gates of the second couple.  

\begin{figure}[H]
\centering
\includegraphics[height=0.55\linewidth]{images/chapter2/SRAM_CELL.pdf}
\caption{Simple SRAM Cell layout. Inductiveload, Public domain, via Wikimedia Commons.}
\label{fig:sram_cell_layout}
\end{figure}

In Figure \ref{fig:sram_cell_layout}, a simple layout is proposed. In order to have a logic 0 as output (\textit{BL = 0}), M3 is active (thus M4 is not active). So M2 is active (thus M3 is not active). If radiation strikes one of those transistors, can happen that the M3's gate voltage goes low, causing a flip of the configuration and thus a flip of the stored bit. \bigskip

As explained in Section \ref{sec:fpgaarchitecture}, most FPGAs' memory configurations are based on SRAM technology. A fault that occurs in a configuration SRAM of an FPGA can lead to completely disastrous failures compared to traditional SRAM used purely for memory storage. This is because upsets have no effect until an address pointing to a word affected by an upset is read out of SRAM. \bigskip

Luckily, error detection and correction circuits can be used to detect and correct the fault, without causing a failure in the undergoing operations. Those are based on the usage of redundant bits for each word. As an example, Hamming codes to detect and correct single-bit error, SEC-DED (Single Error Correction - Double Error Detection) to correct a single error and detect one or double errors, or SEC-DED-DAEC \cite{9418432} (Single Error Correction-Double Error Detection-Double Adjacent Error Correction) to correct adjacent errors in multiple words. An example of error detection circuitry is shown in Figure \ref{fig:sram_det}.

\begin{figure}[H]
\centering
\includegraphics[width=1.0\linewidth]{images/chapter2/sram_detect.pdf}
\caption{Example of error-detection circuitry in SRAM.}
\label{fig:sram_det}
\end{figure}

In an FPGA, the configuration SRAM is not utilized the same way as traditional SRAM. Indeed, direct (logic) connections from the configuration to the user logic exist. If an upset occurs in a used configuration bit, then upset occurs in logic. Because of this difference in the SRAM usage (not dealing with data words anymore but every bit is meaningful at any moment), traditional SRAM detection and corrections schemes can't be applied to FPGAs anymore. If a bitflip occurs, the FPGA configuration itself is modified, leading to a malfunction of a module or a routing modification.\bigskip

The actual technology trend see scaling down to smaller sizes \cite{4033480}, trying to pack more transistors in less area. This scaling affects how radiations modify the behavior of the devices. Those devices are generally less affected by cumulative damage, which means that total ionizing dose or displacement damages are less likely to occur due to the smaller area of each transistor so less area where charges can accumulate or material displacement. On the other hand, Single Event Effects are more likely to occur, because a single particle can hit more than one transistor, causing more complex damage like multiple bit-flips at once. 
